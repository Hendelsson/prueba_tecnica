from google.colab import drive
import os
from pyspark.sql import SparkSession

from extraccion import Extraccion
from transformacion import Transformacion
from carga import Carga



# 2ï¸âƒ£ Definir rutas de entrada y salida en Google Drive
base_path = "/content/drive/MyDrive/etl_project"
input_path = os.path.join(base_path, "Films_2.xlsx")
output_path = os.path.join(base_path, "output")

# Crear la carpeta de salida si no existe
if not os.path.exists(output_path):
    os.makedirs(output_path)

# 3ï¸âƒ£ Iniciar sesiÃ³n de Spark
spark = SparkSession.builder.appName("ETL_Main").getOrCreate()

# 4ï¸âƒ£ Proceso ETL

## ğŸ”¸ ExtracciÃ³n
extraccion = Extraccion(input_path)
dataframes = extraccion.extraer_datos()

## ğŸ”¸ TransformaciÃ³n
transformacion = Transformacion()
dataframes = transformacion.transformar_datos(dataframes)

## ğŸ”¸ Carga
carga = Carga(base_path)
carga.cargar_datos(dataframes)

print("ğŸš€ ETL completado exitosamente. Los archivos Parquet estÃ¡n en Google Drive en la carpeta 'etl_project/output'.")

